
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="zh">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>500 Lines or Less | A Rejection Sampler &#8212; Learn-Computer-and-Math-again 0.0.1 文档</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="lines-or-less-a-rejection-sampler">
<h1>500 Lines or Less | A Rejection Sampler<a class="headerlink" href="#lines-or-less-a-rejection-sampler" title="永久链接至标题">¶</a></h1>
<div class="container"><div class="row"><div class="hero-unit"><p><a href="#id1"><span class="problematic" id="id2">``</span></a>_
.. rubric:: A Rejection Sampler</p>
<blockquote>
<div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">name:</th><td class="field-body">a-rejection-sampler</td>
</tr>
</tbody>
</table>
</div></blockquote>
<p class="author rubric" id="jessica-b-hamrick">Jessica B. Hamrick</p>
</div></div><div class="row"><div id="content" class="span10 offset1"><p><em>Jess is a Ph.D. student at UC Berkeley where she studies human
cognition by combining probabilistic models from machine learning with
behavioral experiments from cognitive science. In her spare time, Jess
is a core contributor to IPython and Jupyter. She also holds a B.S. and
M.Eng. in Computer Science from MIT.</em></p>
<p class="rubric" id="introduction">Introduction</p>
<p>Frequently, in computer science and engineering, we run into problems
that can't be solved using an equation. These problems usually involve
complex systems, noisy inputs, or both. Here are just a few examples of
real-world problems that do not have exact, analytic solutions:</p>
<ol class="arabic simple">
<li>You have built a computer model of an airplane, and want to determine
how well the airplane will hold up under different weather
conditions.</li>
<li>You want to determine whether chemical runoff from a proposed factory
will affect the water supply of nearby residents, based on a model of
groundwater diffusion.</li>
<li>You have a robot which captures noisy images from its camera, and
want to recover the three-dimensional structure of the object that
those images depict.</li>
<li>You want to compute how likely you are to win at chess if you take a
particular move.</li>
</ol>
<p>Even though these types of problems cannot be solved exactly, we can
often achieve an approximate solution to them using techniques known as
<em>Monte Carlo sampling</em> methods. In Monte Carlo methods, the key idea is
to take many <em>samples</em>, which will then allow you to estimate the
solution.<a class="reference external" href="#fn1">:sup:`1`</a></p>
<p class="rubric" id="what-is-sampling">What is Sampling?</p>
<p>The term <em>sampling</em> means generating random values from some probability
distribution. For example, the value you get from rolling a six-sided
die is a sample. The card you draw from the top of the deck after it has
been shuffled is a sample. The location where the dart hits the board is
also a sample. The only difference between these various samples is that
they are generated from different <em>probability distributions</em>. In the
case of the die, the distribution places equal weight across six values.
In the case of the card, the distribution places equal weight across 52
values. In the case of the dart board, the distribution places weight
across a circular area (though it might not be uniformly distributed,
depending on your skill as a dart player).</p>
<p>There are two ways we usually want to use samples. The first is just to
generate a random value to be used later: for example, randomly drawing
cards in a computer game of poker. The second way that samples are used
is for estimation. For example, if you suspected that your friend was
playing with loaded dice, you might want to roll the dice many times to
see if some numbers came up more often than you would expect. Or, you
might just want to characterize the range of possibilities, as in the
airplane example above. Weather is a fairly chaotic system, meaning that
it is impossible to compute <em>exactly</em> whether the airplane will survive
a particular weather situation. Instead, you could simulate the behavior
of the airplane under many different weather conditions, multiple times,
which would allow you to see under which conditions the airplane is most
likely to fail.</p>
<p class="rubric" id="programming-with-samples-and-probabilities">Programming with Samples and Probabilities</p>
<p>As with most applications in computer science, you can make design
decisions when programming with samples and probabilities that will
influence the overall cleanliness, coherence, and correctness of your
code. In this chapter, we will go through a simple example of how to
sample random items in a computer game. In particular, we will focus on
the design decisions which are specific to working with probabilities,
including functions both for sampling and for evaluating probabilities,
working with logarithms, allowing reproducibility, and separating the
process of generating samples from the specific application.</p>
<p class="rubric" id="a-brief-aside-about-notation">A Brief Aside About Notation</p>
<p>We will use mathematical notation like \(p(x)\) to indicate that
\(p\) is the <em>probability density function</em> (PDF) or <em>probability mass
function</em> (PMF) over values \(x\) of a random variable. A PDF is a
<em>continuous</em> function \(p(x)\) such that \(\int_{-\infty}^\infty
p(x)\ \mathrm{d}x=1\), whereas a PMF is a <em>discrete</em> function
\(p(x)\) such that \(\sum_{x\in \mathbb{Z}} p(x)=1\), where
\(\mathbb{Z}\) is the set of all integers.</p>
<p>The probability distribution in the case of the dart board would be a
continuous PDF, while the probability distribution in the case of a die
would be a discrete PMF. In both cases, \(p(x) \geq 0\) for all
\(x\); i.e., the probabilities have to be non-negative.</p>
<p>There are two things that we might want to do with a probability
distribution. Given a value (or location) \(x\), we might want to
<em>evaluate</em> what the probability density (or mass) is at that location.
In mathematical notation, we would write this as \(p(x)\) (the
probability density at the value \(x\)).</p>
<p>Given the PDF or PMF, we might also want to <em>sample</em> a value \(x\) in
a manner proportional to the distribution (such that we are more likely
to get a sample at places where the probability is higher). In
mathematical notation, we write this as \(x\sim p\), to indicate that
\(x\) is sampled proportional to \(p\).</p>
<p class="rubric" id="sampling-magical-items">Sampling Magical Items</p>
<p>As a simple example to demonstrate the various design decisions involved
with programming with probabilities, let's imagine we're writing a
roleplaying game (RPG). We would like a method of generating bonus stats
for the magical items that are randomly dropped by monsters. We might
decide that the maximum bonus we want an item to confer is +5, and that
higher bonuses are less likely than lower bonuses. If \(B\) is a
random variable over the values of the bonus, then:</p>
<p>\[ p(B=\mathrm{+1}) = 0.55\\ p(B=\mathrm{+2}) = 0.25\\
p(B=\mathrm{+3}) = 0.12\\ p(B=\mathrm{+4}) = 0.06\\
p(B=\mathrm{+5}) = 0.02 \]</p>
<p>We can also specify that there are six stats (dexterity, constitution,
strength, intelligence, wisdom, and charisma) that our bonus should be
distributed between. So, an item with a +5 bonus could have those points
distributed across different stats (e.g., +2 wisdom and +3 intelligence)
or concentrated within a single stat (e.g., +5 charisma).</p>
<p>How would we randomly sample from this distribution? The easiest way is
probably to first sample the overall item bonus, then sample the way the
bonus is distributed across the stats. Conveniently, the probability
distributions of the bonus and the way that it is distributed are both
instances of the <em>multinomial distribution</em>.</p>
<p class="rubric" id="the-multinomial-distribution">The Multinomial Distribution</p>
<p>The multinomial distribution is used when you have several possible
outcomes, and you want to characterize the probability of each of those
outcomes occurring. The classic example used to explain the multinomial
distribution is the <em>ball and urn</em>. The idea is that you have an urn
with different colored balls in it (for example, 30% red, 20% blue, and
50% green). You pull out a ball, record its color, put it back in the
urn, and then repeat this multiple times. In this case, an <em>outcome</em>
corresponds to drawing a ball of a particular color, and the probability
of each outcome corresponds to the proportion of balls of that color
(e.g., for the outcome of drawing a blue ball, the probability is
\(p(\mathrm{blue})=0.20\)). The multinomial distribution is then used
to describe the possible combinations of outcomes when multiple balls
are drawn (e.g., two green and one blue).</p>
<p>The code in this section is located in the file <code class="docutils literal"><span class="pre">multinomial.py</span></code>.</p>
<p class="rubric" id="the-multinomialdistribution-class">The <code class="docutils literal"><span class="pre">MultinomialDistribution</span></code> Class</p>
<p>In general, there are two use cases for a distribution: we might want to
<em>sample</em> from that distribution, and we might want to <em>evaluate the
probability</em> of a sample (or samples) under that distribution's PMF or
PDF. While the actual computations needed to perform these two functions
are fairly different, they rely on a common piece of information: what
the <em>parameters</em> of the distribution are. In the case of the multinomial
distribution, the parameters are the event probabilities, \(p\) (which
correspond to the proportions of the different colored balls in the urn
example above).</p>
<p>The simplest solution would be to simply create two functions that both
take the same parameters, but are otherwise independent. However, I will
usually opt to use a class for representing my distributions. There are
several advantages to doing so:</p>
<ol class="arabic simple">
<li>You only need to pass in the parameters once, when creating the
class.</li>
<li>There are additional attributes we might want to know about a
distribution: the mean, variance, derivative, etc. Once we have even
a handful of functions that operate on a common object, it is even
more convenient to use a class rather than passing the same
parameters to many different functions.</li>
<li>It is usually a good idea to check that the parameter values are
valid (for example, in the case of the multinomial distribution, the
vector \(p\) of event probabilities should sum to 1). It is much
more efficient to do this check once, in the constructor of the
class, rather than every time one of the functions is called.</li>
<li>Sometimes computing the PMF or PDF involves computing constant values
(given the parameters). With a class, we can pre-compute these
constants in the constructor, rather than having to compute them
every time the PMF or PDF function is called.</li>
</ol>
<p>In practice, this is how many statistics packages work, including
SciPy's own distributions, which are located in the <code class="docutils literal"><span class="pre">scipy.stats</span></code>
module. While we are using other SciPy functions, however, we are not
using their probability distributions, both for the sake of
illustration, and because there is currently no multinomial distribution
in SciPy.</p>
<p>Here is the constructor code for the class:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">MultinomialDistribution</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">rso</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the multinomial random variable.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        p: numpy array of length `k`</span>
<span class="sd">            The event probabilities</span>
<span class="sd">        rso: numpy RandomState object (default: None)</span>
<span class="sd">            The random number generator</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Check that the probabilities sum to 1. If they don&#39;t, then</span>
        <span class="c1"># something is wrong! We use `np.isclose` rather than checking</span>
        <span class="c1"># for exact equality because in many cases, we won&#39;t have</span>
        <span class="c1"># exact equality due to floating-point error.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;event probabilities do not sum to 1&quot;</span><span class="p">)</span>

        <span class="c1"># Store the parameters that were passed in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rso</span> <span class="o">=</span> <span class="n">rso</span>

        <span class="c1"># Precompute log probabilities, for use by the log-PMF, for</span>
        <span class="c1"># each element of `self.p` (the function `np.log` operates</span>
        <span class="c1"># elementwise over NumPy arrays, as well as on scalars.)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
<p>The class takes as arguments the event probabilities, \(p\), and a
variable called <code class="docutils literal"><span class="pre">rso</span></code>. First, the constructor checks that the
parameters are valid; i.e., that <code class="docutils literal"><span class="pre">p</span></code> sums to 1. Then it stores the
arguments that were passed in, and uses the event probabilities to
compute the event <em>log</em> probabilities. (We'll go into why this is
necessary in a bit). The <code class="docutils literal"><span class="pre">rso</span></code> object is what we'll use later to
produce random numbers. (We'll talk more about what it is a bit later as
well).</p>
<p>Before we get into the rest of the class, let's go over two points
related to the constructor.</p>
<p class="rubric" id="descriptive-versus-mathematic-variable-names">Descriptive versus Mathematic Variable Names</p>
<p>Usually, programmers are encouraged to use descriptive variable names:
for example, it would be considered better practice to use the names
<code class="docutils literal"><span class="pre">independent_variable</span></code> and <code class="docutils literal"><span class="pre">dependent_variable</span></code> rather than <code class="docutils literal"><span class="pre">x</span></code>
and <code class="docutils literal"><span class="pre">y</span></code>. A standard rule of thumb is to never use variable names that
are only one or two characters. However, you'll notice that in the
constructor to our <code class="docutils literal"><span class="pre">MultinomialDistribution</span></code> class, we use the
variable name of <code class="docutils literal"><span class="pre">p</span></code>, which is in violation of typical naming
conventions.</p>
<p>While I agree that such naming conventions should apply in almost every
domain, there is one exception: math. The difficulty with coding up
mathematical equations is that those equations usually have variable
names which are just a single letter: \(x\), \(y\), \(\alpha\),
etc. So, if you were translating them directly into code, the easiest
variable names would be <code class="docutils literal"><span class="pre">x</span></code>, <code class="docutils literal"><span class="pre">y</span></code>, and <code class="docutils literal"><span class="pre">alpha</span></code>. Obviously, these
are not the most informative variable names (the name <code class="docutils literal"><span class="pre">x</span></code> does not
convey much information), but having more descriptive variable names can
also make it harder to switch between the the code and the equation.</p>
<p>I think that when you are writing code that directly implements an
equation, the same variable names should be used as those in the
equation. This makes it easy to see which parts of the code are
implementing which pieces of the equation. This, of course, can make the
code harder to understand in isolation, so it is especially important
that the comments then do a good job of explaining what the goal of the
various computations are. If the equation is listed in an academic
paper, the comments should reference the equation number so it can be
easily looked up.</p>
<p class="rubric" id="importing-numpy">Importing NumPy</p>
<p>You may have noticed that we imported the <code class="docutils literal"><span class="pre">numpy</span></code> module as <code class="docutils literal"><span class="pre">np</span></code>.
This is standard practice in the world of numerical computing, because
NumPy provides a huge number of useful functions, many of which might be
used even in a single file. In the simple examples from this chapter, we
only use eleven NumPy functions, but the number can be much higher: it
is not uncommon for me to use around forty different NumPy functions
throughout a project!</p>
<p>There are a few options for importing NumPy. We could use
<code class="docutils literal"><span class="pre">from</span> <span class="pre">numpy</span> <span class="pre">import</span> <span class="pre">*</span></code>, but that is generally poor style, because it
makes it hard to determine where the functions came from. We could
import the functions individually with
<code class="docutils literal"><span class="pre">from</span> <span class="pre">numpy</span> <span class="pre">import</span> <span class="pre">array,</span> <span class="pre">log,</span> <span class="pre">...</span></code>, but that gets clumsy fairly
quickly. We could just use <code class="docutils literal"><span class="pre">import</span> <span class="pre">numpy</span></code>, but this often results in
code being much more difficult to read. Both of the following examples
are hard to read, but the one using <code class="docutils literal"><span class="pre">np</span></code> rather than <code class="docutils literal"><span class="pre">numpy</span></code> is
significantly clearer:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b</span><span class="p">))))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b</span><span class="p">))))</span>
</pre></div>
</div>
<p class="rubric" id="sampling-from-a-multinomial-distribution">Sampling from a Multinomial Distribution</p>
<p>Taking a sample from a multinomial distribution is actually fairly
straightforward, because NumPy provides us with a function that does it:
<code class="docutils literal"><span class="pre">np.random.multinomial</span></code><a class="reference external" href="#fn2">:sup:`2`</a>.</p>
<p>Despite the fact that this function already exists, there are a few
design decisions surrounding it that we can make.</p>
<p class="rubric" id="seeding-the-random-number-generator">Seeding the Random Number Generator</p>
<p>Even though we do want to draw a <em>random</em> sample, we sometimes want our
results to be reproducible: even though the numbers seem random, if we
were to run the program again, we might want it to use the <em>same</em>
sequence of &quot;random&quot; numbers.</p>
<p>In order to allow for the generation of such &quot;reproducibly random&quot;
numbers, we need to tell our sampling function <em>how</em> to generate the
random numbers. We can accomplish this through use of a NumPy
<code class="docutils literal"><span class="pre">RandomState</span></code> object, which is essentially a random number generator
object that can be passed around. It has most of the same functions as
<code class="docutils literal"><span class="pre">np.random</span></code>; the difference is that we get to control where the random
numbers come from. We create it as follows:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rso</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">230489</span><span class="p">)</span>
</pre></div>
</div>
<p>where the number passed to the <code class="docutils literal"><span class="pre">RandomState</span></code> constructor is the <em>seed</em>
for the random number generator. As long as we instantiate it with the
same seed, a <code class="docutils literal"><span class="pre">RandomState</span></code> object will produce the same &quot;random&quot;
numbers in the same order, thus ensuring replicability:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rso</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
<span class="go">0.5356709186237074</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rso</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
<span class="go">0.6190581888276206</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rso</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
<span class="go">0.23143573416770336</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rso</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">230489</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rso</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
<span class="go">0.5356709186237074</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rso</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
<span class="go">0.6190581888276206</span>
</pre></div>
</div>
<p>Earlier, we saw that the constructor took an argument called <code class="docutils literal"><span class="pre">rso</span></code>.
This <code class="docutils literal"><span class="pre">rso</span></code> variable is a <code class="docutils literal"><span class="pre">RandomState</span></code> object that has already been
initialized. I like to make the <code class="docutils literal"><span class="pre">RandomState</span></code> object an optional
parameter: it is occasionally convenient to not be <em>forced</em> to use it,
but I do want to have the <em>option</em> of using it (which, if I were to just
use the <code class="docutils literal"><span class="pre">np.random</span></code> module, I would not be able to do).</p>
<p>So, if the <code class="docutils literal"><span class="pre">rso</span></code> variable is not given, then the constructor defaults
to <code class="docutils literal"><span class="pre">np.random.multinomial</span></code>. Otherwise, it uses the multinomial sampler
from the <code class="docutils literal"><span class="pre">RandomState</span></code> object itself<a class="reference external" href="#fn3">:sup:`3`</a>.</p>
<p class="rubric" id="whats-a-parameter">What's a Parameter?</p>
<p>Once we've decided whether to use <code class="docutils literal"><span class="pre">np.random.multinomial</span></code> or
<code class="docutils literal"><span class="pre">rso.multinomial</span></code>, sampling is just a matter of calling the
appropriate function. However, there is one other decision that we might
consider: What counts as a parameter?</p>
<p>Earlier, I said that the outcome probabilities, \(p\), were the
parameters of the multinomial distribution. However, depending on who
you ask, the number of events, \(n\), can <em>also</em> be a parameter of the
multinomial distribution. So, why didn't we include \(n\) as an
argument to the constructor?</p>
<p>This question, while relatively specific to the multinomial
distribution, actually comes up fairly frequently when dealing with
probability distributions, and the answer really depends on the use
case. For a multinomial, can you make the assumption that the number of
events is always the same? If so, then it might be better to pass in
\(n\) as an argument to the constructor. If not, then requiring
\(n\) to be specified at object creation time could be very
restrictive, and might even require you to create a new distribution
object every time you need to draw a sample!</p>
<p>I usually don't like to be that restricted by my code, and thus choose
to have <code class="docutils literal"><span class="pre">n</span></code> be an argument to the <code class="docutils literal"><span class="pre">sample</span></code> function, rather than
having it be an argument to the constructor. An alternate solution could
be to have <code class="docutils literal"><span class="pre">n</span></code> be an argument to the constructor, but also include
methods to allow for the value of <code class="docutils literal"><span class="pre">n</span></code> to be changed, without having to
create an entirely new object. For our purposes, though, this solution
is probably overkill, so we'll stick to just having it be an argument to
<code class="docutils literal"><span class="pre">sample</span></code>:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Samples draws of `n` events from a multinomial distribution with</span>
<span class="sd">    outcome probabilities `self.p`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n: integer</span>
<span class="sd">        The number of total events</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy array of length `k`</span>
<span class="sd">        The sampled number of occurrences for each outcome</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rso</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p class="rubric" id="evaluating-the-multinomial-pmf">Evaluating the Multinomial PMF</p>
<p>Although we don't explicitly need to compute the probability of the
magical items that we generate, it is almost always a good idea to write
a function that can compute the distribution's probability mass function
(PMF) or probability density function (PDF). Why?</p>
<p>One reason is that we can use it for testing: if we take many samples
with our sampling function, then they should approximate the exact PDF
or PMF. If after many samples the approximation is poor or obviously
wrong, then we know there is a bug in our code somewhere.</p>
<p>Another reason to implement the PMF or PDF is that frequently, you will
actually need it later down the line and simply don't realize it
initially. For example, we might want to classify our randomly generated
items as <em>common</em>, <em>uncommon</em>, and <em>rare</em>, depending on how likely they
are to be generated. To determine this, we need to be able to compute
the PMF.</p>
<p>Finally, in many cases, your particular use case will dictate that you
implement the PMF or PDF from the beginning, anyway.</p>
<p class="rubric" id="the-multinomial-pmf-equation">The Multinomial PMF Equation</p>
<p>Formally, the multinomial distribution has the following equation:</p>
<p>\[ p(\mathbf{x}; \mathbf{p}) = \frac{(\sum_{i=1}^k
x_i)!}{x_1!\cdots{}x_k!}p_1^{x_1}\cdots{}p_k^{x_k} \]</p>
<p>where \(\mathbf{x}=[x_1, \ldots{}, x_k]\) is a vector of length
\(k\) specifying the number of times each event happened, and
\(\mathbf{p}=[p_1, \ldots{}, p_k]\) is a vector specifying the
probability of each event occurring. As mentioned above, the event
probabilities \(\mathbf{p}\) are the <em>parameters</em> of the
distribution.</p>
<p>The factorials in the equation above can actually be expressed using a
special function, \(\Gamma\), called the <em>gamma function</em>. When we
get to writing the code, it will be more convenient and efficient to use
the gamma function rather than factorial, so we will rewrite the
equation using \(\Gamma\):</p>
<p>\[ p(\mathbf{x}; \mathbf{p}) = \frac{\Gamma((\sum_{i=1}^k
x_i)+1)}{\Gamma(x_1+1)\cdots{}\Gamma(x_k+1)}p_1^{x_1}\cdots{}p_k^{x_k}
\]</p>
<p class="rubric" id="working-with-log-values">Working with Log Values</p>
<p>Before getting into the actual code needed to implement the equation
above, I want to emphasize one of the the most important design
decisions when writing code with probabilities: working with log values.
What this means is that rather than working directly with probabilities
\(p(x)\), we should be working with <em>log</em>-probabilities,
\(\log{p(x)}\). This is because probabilities can get very small very
quickly, resulting in underflow errors.</p>
<p>To motivate this, consider that probabilities must range between 0 and 1
(inclusive). NumPy has a useful function, <code class="docutils literal"><span class="pre">finfo</span></code>, that will tell us
the limits of floating point values for our system. For example, on a
64-bit machine, we see that the smallest usable positive number (given
by <code class="docutils literal"><span class="pre">tiny</span></code>) is:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">tiny</span>
<span class="go">2.2250738585072014e-308</span>
</pre></div>
</div>
<p>While that may seem very small, it is not unusual to encounter
probabilities of this magnitude, or even smaller. Moreover, it is a
common operation to multiply probabilities, yet if we try to do this
with very small probabilities, we encounter underflow problems:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tiny</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">tiny</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># if we multiply numbers that are too small, we lose all precision</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tiny</span> <span class="o">*</span> <span class="n">tiny</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p>However, taking the log can help alleviate this issue because we can
represent a much wider range of numbers with logarithms than we can
normally. Officially, log values range from \(-\infty\) to zero. In
practice, they range from the <code class="docutils literal"><span class="pre">min</span></code> value returned by <code class="docutils literal"><span class="pre">finfo</span></code>, which
is the smallest number that can be represented, to zero. The <code class="docutils literal"><span class="pre">min</span></code>
value is <em>much</em> smaller than the log of the <code class="docutils literal"><span class="pre">tiny</span></code> value (which would
be our lower bound if we did not work in log space):</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># this is our lower bound normally</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tiny</span><span class="p">)</span>
<span class="go">-708.39641853226408</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># this is our lower bound when using logs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">min</span>
<span class="go">-1.7976931348623157e+308</span>
</pre></div>
</div>
<p>So, by working with log values, we can greatly expand our range of
representable numbers. Moreover, we can perform multiplication with logs
by using addition, because \(\log(x\cdot{}y) = \log(x) +
\log(y)\). Thus, if we do the multiplication above with logs, we do
not have to worry (as much) about loss of precision due to underflow:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># the result of multiplying small probabilities</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tiny</span> <span class="o">*</span> <span class="n">tiny</span><span class="p">)</span>
<span class="go">-inf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># the result of adding small log probabilities</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tiny</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tiny</span><span class="p">)</span>
<span class="go">-1416.7928370645282</span>
</pre></div>
</div>
<p>Of course, this solution is not a magic bullet. If we need to derive the
number from the logarithm (for example, to add probabilities, rather
than multiply them), then we are back to underflow:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tiny</span><span class="o">*</span><span class="n">tiny</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tiny</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tiny</span><span class="p">))</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p>Still, doing all our computations with logs can save a lot of headache.
We might be forced to lose that precision if we need to go back to the
original numbers, but we at least maintain <em>some</em> information about the
probabilities—enough to compare them, for example—that would otherwise
be lost.</p>
<p class="rubric" id="writing-the-pmf-code">Writing the PMF Code</p>
<p>Now that we have seen the importance of working with logs, we can
actually write our function to compute the log-PMF:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">log_pmf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluates the log-probability mass function (log-PMF) of a</span>
<span class="sd">    multinomial with outcome probabilities `self.p` for a draw `x`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x: numpy array of length `k`</span>
<span class="sd">        The number of occurrences of each outcome</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    The evaluated log-PMF for draw `x`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Get the total number of events</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># equivalent to log(n!)</span>
    <span class="n">log_n_factorial</span> <span class="o">=</span> <span class="n">gammaln</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># equivalent to log(x1! * ... * xk!)</span>
    <span class="n">sum_log_xi_factorial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gammaln</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># If one of the values of self.p is 0, then the corresponding</span>
    <span class="c1"># value of self.logp will be -inf. If the corresponding value</span>
    <span class="c1"># of x is 0, then multiplying them together will give nan, but</span>
    <span class="c1"># we want it to just be 0.</span>
    <span class="n">log_pi_xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logp</span> <span class="o">*</span> <span class="n">x</span>
    <span class="n">log_pi_xi</span><span class="p">[</span><span class="n">x</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># equivalent to log(p1^x1 * ... * pk^xk)</span>
    <span class="n">sum_log_pi_xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_pi_xi</span><span class="p">)</span>

    <span class="c1"># Put it all together</span>
    <span class="n">log_pmf</span> <span class="o">=</span> <span class="n">log_n_factorial</span> <span class="o">-</span> <span class="n">sum_log_xi_factorial</span> <span class="o">+</span> <span class="n">sum_log_pi_xi</span>
    <span class="k">return</span> <span class="n">log_pmf</span>
</pre></div>
</div>
<p>For the most part, this is a straightforward implementation of the
equation above for the multinomial PMF. The <code class="docutils literal"><span class="pre">gammaln</span></code> function is from
<code class="docutils literal"><span class="pre">scipy.special</span></code>, and computes the log-gamma function,
\(\log{\Gamma(x)}\). As mentioned above, it is more convenient to
use the gamma function rather than a factorial function; this is because
SciPy gives us a log-gamma function, but not a log-factorial function.
We could have computed a log factorial ourselves, using something like:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">log_n_factorial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)))</span>
<span class="n">sum_log_xi_factorial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
</pre></div>
</div>
<p>but it is easier to understand, easier to code, and more computationally
efficient if we use the gamma function already built in to SciPy.</p>
<p>There is one edge case that we need to tackle: when one of our
probabilities is zero. When \(p_i=0\), then
\(\log{p_i}=-\infty\). This would be fine, except for the following
behavior when infinity is multiplied by zero:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># it&#39;s fine to multiply infinity by integers...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="o">*</span> <span class="mf">2.0</span>
<span class="go">-inf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># ...but things break when we try to multiply by zero</span>
<span class="gp">&gt;&gt;&gt; </span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="o">*</span> <span class="mf">0.0</span>
<span class="go">nan</span>
</pre></div>
</div>
<p><code class="docutils literal"><span class="pre">nan</span></code> means &quot;not a number&quot;, and it is almost always a pain to deal
with, because most computations with <code class="docutils literal"><span class="pre">nan</span></code> result in another <code class="docutils literal"><span class="pre">nan</span></code>.
So, if we don't handle the case where \(p_i=0\) and \(x_i=0\), we
will end up with a <code class="docutils literal"><span class="pre">nan</span></code>. That will get summed with other numbers,
producing another <code class="docutils literal"><span class="pre">nan</span></code>, which is just not useful. To handle this, we
check specifically for the case when \(x_i=0\), and set the resulting
\(x_i\cdot{}\log(p_i)\) also to zero.</p>
<p>Let's return for a moment to our discussion of using logs. Even if we
really only need the PMF, and not the log-PMF, it is generally better to
<em>first</em> compute it with logs, and then exponentiate it if we need to:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pmf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluates the probability mass function (PMF) of a multinomial</span>
<span class="sd">    with outcome probabilities `self.p` for a draw `x`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x: numpy array of length `k`</span>
<span class="sd">        The number of occurrences of each outcome</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    The evaluated PMF for draw `x`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pmf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_pmf</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">pmf</span>
</pre></div>
</div>
<p>To further drive home the importance of working with logs, we can look
at an example with just the multinomial:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span> <span class="o">=</span> <span class="n">MultinomialDistribution</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span><span class="o">.</span><span class="n">log_pmf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="go">-1386.2943611198905</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span><span class="o">.</span><span class="n">log_pmf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">999</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="go">-1384.9080667587707</span>
</pre></div>
</div>
<p>In this case, we get <em>extremely</em> small probabilities (which, you will
notice, are much smaller than the <code class="docutils literal"><span class="pre">tiny</span></code> value we discussed above).
This is because the fraction in the PMF is huge: 1000 factorial can't
even be computed due to overflow. But, the <em>log</em> of the factorial can
be:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="k">import</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">gammaln</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gamma</span><span class="p">(</span><span class="mi">1000</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">inf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gammaln</span><span class="p">(</span><span class="mi">1000</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">5912.1281784881639</span>
</pre></div>
</div>
<p>If we had tried to compute just the PMF using the <code class="docutils literal"><span class="pre">gamma</span></code> function, we
would have ended up with <code class="docutils literal"><span class="pre">gamma(1000</span> <span class="pre">+</span> <span class="pre">1)</span> <span class="pre">/</span> <span class="pre">gamma(1000</span> <span class="pre">+</span> <span class="pre">1)</span></code>, which
results in a <code class="docutils literal"><span class="pre">nan</span></code> value (even though we can see that it should be 1).
But, because we do the computation with logarithms, it's not an issue
and we don't need to worry about it!</p>
<p class="rubric" id="sampling-magical-items-revisited">Sampling Magical Items, Revisited</p>
<p>Now that we have written our multinomial functions, we can put them to
work to generate our magical items. To do this, we will create a class
called <code class="docutils literal"><span class="pre">MagicItemDistribution</span></code>, located in the file <code class="docutils literal"><span class="pre">rpg.py</span></code>:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MagicItemDistribution</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="c1"># these are the names (and order) of the stats that all magical</span>
    <span class="c1"># items will have</span>
    <span class="n">stats_names</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dexterity&quot;</span><span class="p">,</span> <span class="s2">&quot;constitution&quot;</span><span class="p">,</span> <span class="s2">&quot;strength&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;intelligence&quot;</span><span class="p">,</span> <span class="s2">&quot;wisdom&quot;</span><span class="p">,</span> <span class="s2">&quot;charisma&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bonus_probs</span><span class="p">,</span> <span class="n">stats_probs</span><span class="p">,</span> <span class="n">rso</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize a magic item distribution parameterized by `bonus_probs`</span>
<span class="sd">        and `stats_probs`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        bonus_probs: numpy array of length m</span>
<span class="sd">            The probabilities of the overall bonuses. Each index in</span>
<span class="sd">            the array corresponds to the bonus of that amount (e.g.,</span>
<span class="sd">            index 0 is +0, index 1 is +1, etc.)</span>

<span class="sd">        stats_probs: numpy array of length 6</span>
<span class="sd">            The probabilities of how the overall bonus is distributed</span>
<span class="sd">            among the different stats. `stats_probs[i]` corresponds to</span>
<span class="sd">            the probability of giving a bonus point to the ith stat;</span>
<span class="sd">            i.e., the value at `MagicItemDistribution.stats_names[i]`.</span>

<span class="sd">        rso: numpy RandomState object (default: np.random)</span>
<span class="sd">            The random number generator</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Create the multinomial distributions we&#39;ll be using</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bonus_dist</span> <span class="o">=</span> <span class="n">MultinomialDistribution</span><span class="p">(</span><span class="n">bonus_probs</span><span class="p">,</span> <span class="n">rso</span><span class="o">=</span><span class="n">rso</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stats_dist</span> <span class="o">=</span> <span class="n">MultinomialDistribution</span><span class="p">(</span><span class="n">stats_probs</span><span class="p">,</span> <span class="n">rso</span><span class="o">=</span><span class="n">rso</span><span class="p">)</span>
</pre></div>
</div>
<p>The constructor to our <code class="docutils literal"><span class="pre">MagicItemDistribution</span></code> class takes parameters
for the bonus probabilities, the stats probabilities, and the random
number generator. Even though we specified above what we wanted the
bonus probabilities to be, it is generally a good idea to encode
parameters as arguments that are passed in. This leaves open the
possibility of sampling items under different distributions. (For
example, maybe the bonus probabilities would change as the player's
level increases.) We encode the <em>names</em> of the stats as a class
variable, <code class="docutils literal"><span class="pre">stats_names</span></code>, though this could just as easily be another
parameter to the constructor.</p>
<p>As mentioned previously, there are two steps to sampling a magical item:
first sampling the overall bonus, and then sampling the distribution of
the bonus across the stats. As such, we code these steps as two methods:
<code class="docutils literal"><span class="pre">_sample_bonus</span></code> and <code class="docutils literal"><span class="pre">_sample_stats</span></code>:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_sample_bonus</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sample a value of the overall bonus.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    integer</span>
<span class="sd">        The overall bonus</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># The bonus is essentially just a sample from a multinomial</span>
    <span class="c1"># distribution with n=1; i.e., only one event occurs.</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonus_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># `sample` is an array of zeros and a single one at the</span>
    <span class="c1"># location corresponding to the bonus. We want to convert this</span>
    <span class="c1"># one into the actual value of the bonus.</span>
    <span class="n">bonus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bonus</span>

<span class="k">def</span> <span class="nf">_sample_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sample the overall bonus and how it is distributed across the</span>
<span class="sd">    different stats.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy array of length 6</span>
<span class="sd">        The number of bonus points for each stat</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># First we need to sample the overall bonus</span>
    <span class="n">bonus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_bonus</span><span class="p">()</span>

    <span class="c1"># Then, we use a different multinomial distribution to sample</span>
    <span class="c1"># how that bonus is distributed. The bonus corresponds to the</span>
    <span class="c1"># number of events.</span>
    <span class="n">stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stats_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">bonus</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">stats</span>
</pre></div>
</div>
<p>We <em>could</em> have made these a single method—especially since
<code class="docutils literal"><span class="pre">_sample_stats</span></code> is the only function that depends on
<code class="docutils literal"><span class="pre">_sample_bonus</span></code>—but I have chosen to keep them separate, both because
it makes the sampling routine easier to understand, and because breaking
it up into smaller pieces makes the code easier to test.</p>
<p>You'll also notice that these methods are prefixed with an underscore,
indicating that they're not really meant to be used outside the class.
Instead, we provide the function <code class="docutils literal"><span class="pre">sample</span></code>:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sample a random magical item.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dictionary</span>
<span class="sd">        The keys are the names of the stats, and the values are</span>
<span class="sd">        the bonus conferred to the corresponding stat.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_stats</span><span class="p">()</span>
    <span class="n">item_stats</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stats_names</span><span class="p">,</span> <span class="n">stats</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">item_stats</span>
</pre></div>
</div>
<p>The <code class="docutils literal"><span class="pre">sample</span></code> function does essentially the same thing as
<code class="docutils literal"><span class="pre">_sample_stats</span></code>, except that it returns a dictionary with the stats'
names as keys. This provides a clean and understandable interface for
sampling items—it is obvious which stats have how many bonus points—but
it also keeps open the option of using just <code class="docutils literal"><span class="pre">_sample_stats</span></code> if one
needs to take many samples and efficiency is required.</p>
<p>We use a similar design for evaluating the probability of items. Again,
we expose high-level methods <code class="docutils literal"><span class="pre">pmf</span></code> and <code class="docutils literal"><span class="pre">log_pmf</span></code> which take
dictionaries of the form produced by <code class="docutils literal"><span class="pre">sample</span></code>:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">log_pmf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the log probability of the given magical item.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    item: dictionary</span>
<span class="sd">        The keys are the names of the stats, and the values are</span>
<span class="sd">        the bonuses conferred to the corresponding stat.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The value corresponding to log(p(item))</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># First pull out the bonus points for each stat, in the</span>
    <span class="c1"># correct order, then pass that to _stats_log_pmf.</span>
    <span class="n">stats</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="n">stat</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stats_names</span><span class="p">])</span>
    <span class="n">log_pmf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stats_log_pmf</span><span class="p">(</span><span class="n">stats</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_pmf</span>

<span class="k">def</span> <span class="nf">pmf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the probability the given magical item.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    item: dictionary</span>
<span class="sd">        The keys are the names of the stats, and the values are</span>
<span class="sd">        the bonus conferred to the corresponding stat.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The value corresponding to p(item)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_pmf</span><span class="p">(</span><span class="n">item</span><span class="p">))</span>
</pre></div>
</div>
<p>These methods rely on <code class="docutils literal"><span class="pre">_stats_log_pmf</span></code>, which computes the probability
of the stats (but which takes an array rather than a dictionary):</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_stats_log_pmf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stats</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluate the log-PMF for the given distribution of bonus points</span>
<span class="sd">    across the different stats.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    stats: numpy array of length 6</span>
<span class="sd">        The distribution of bonus points across the stats</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The value corresponding to log(p(stats))</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># There are never any leftover bonus points, so the sum of the</span>
    <span class="c1"># stats gives us the total bonus.</span>
    <span class="n">total_bonus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">stats</span><span class="p">)</span>

    <span class="c1"># First calculate the probability of the total bonus</span>
    <span class="n">logp_bonus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bonus_log_pmf</span><span class="p">(</span><span class="n">total_bonus</span><span class="p">)</span>

    <span class="c1"># Then calculate the probability of the stats</span>
    <span class="n">logp_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stats_dist</span><span class="o">.</span><span class="n">log_pmf</span><span class="p">(</span><span class="n">stats</span><span class="p">)</span>

    <span class="c1"># Then multiply them together (using addition, because we are</span>
    <span class="c1"># working with logs)</span>
    <span class="n">log_pmf</span> <span class="o">=</span> <span class="n">logp_bonus</span> <span class="o">+</span> <span class="n">logp_stats</span>
    <span class="k">return</span> <span class="n">log_pmf</span>
</pre></div>
</div>
<p>The method <code class="docutils literal"><span class="pre">_stats_log_pmf</span></code>, in turn, relies on <code class="docutils literal"><span class="pre">_bonus_log_pmf</span></code>,
which computes the probability of the overall bonus:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_bonus_log_pmf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bonus</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluate the log-PMF for the given bonus.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    bonus: integer</span>
<span class="sd">        The total bonus.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The value corresponding to log(p(bonus))</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Make sure the value that is passed in is within the</span>
    <span class="c1"># appropriate bounds</span>
    <span class="k">if</span> <span class="n">bonus</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">bonus</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonus_dist</span><span class="o">.</span><span class="n">p</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>

    <span class="c1"># Convert the scalar bonus value into a vector of event</span>
    <span class="c1"># occurrences</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonus_dist</span><span class="o">.</span><span class="n">p</span><span class="p">))</span>
    <span class="n">x</span><span class="p">[</span><span class="n">bonus</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonus_dist</span><span class="o">.</span><span class="n">log_pmf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>We can now create our distribution as follows:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">rpg</span> <span class="k">import</span> <span class="n">MagicItemDistribution</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bonus_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.06</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span> <span class="o">/</span> <span class="mf">6.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rso</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">234892</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">item_dist</span> <span class="o">=</span> <span class="n">MagicItemDistribution</span><span class="p">(</span><span class="n">bonus_probs</span><span class="p">,</span> <span class="n">stats_probs</span><span class="p">,</span> <span class="n">rso</span><span class="o">=</span><span class="n">rso</span><span class="p">)</span>
</pre></div>
</div>
<p>Once created, we can use it to generate a few different items:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">item_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="go">{&#39;dexterity&#39;: 0, &#39;strength&#39;: 0, &#39;constitution&#39;: 0,</span>
<span class="go"> &#39;intelligence&#39;: 0, &#39;wisdom&#39;: 0, &#39;charisma&#39;: 1}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">item_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="go">{&#39;dexterity&#39;: 0, &#39;strength&#39;: 0, &#39;constitution&#39;: 1,</span>
<span class="go"> &#39;intelligence&#39;: 0, &#39;wisdom&#39;: 2, &#39;charisma&#39;: 0}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">item_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="go">{&#39;dexterity&#39;: 1, &#39;strength&#39;: 0, &#39;constitution&#39;: 1,</span>
<span class="go"> &#39;intelligence&#39;: 0, &#39;wisdom&#39;: 0, &#39;charisma&#39;: 0}</span>
</pre></div>
</div>
<p>And, if we want, we can evaluate the probability of a sampled item:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">item</span> <span class="o">=</span> <span class="n">item_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">item</span>
<span class="go">{&#39;dexterity&#39;: 0, &#39;strength&#39;: 0, &#39;constitution&#39;: 0,</span>
<span class="go"> &#39;intelligence&#39;: 0, &#39;wisdom&#39;: 2, &#39;charisma&#39;: 0}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">item_dist</span><span class="o">.</span><span class="n">log_pmf</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
<span class="go">-4.9698132995760007</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">item_dist</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
<span class="go">0.0069444444444444441</span>
</pre></div>
</div>
<p class="rubric" id="estimating-attack-damage">Estimating Attack Damage</p>
<p>We've seen one application of sampling: generating random items that
monsters drop. I mentioned earlier that sampling can also be used when
you want to estimate something from the distribution as a whole, and
there are certainly cases in which we could use our
<code class="docutils literal"><span class="pre">MagicItemDistribution</span></code> to do this. For example, let's say that damage
in our RPG works by rolling some number of D12s (twelve-sided dice). The
player gets to roll one die by default, and then add dice according to
their strength bonus. So, for example, if they have a +2 strength bonus,
they can roll three dice. The damage dealt is then the sum of the dice.</p>
<p>We might want to know how much damage a player might deal after finding
some number of weapons; e.g., as a factor in setting the difficulty of
monsters. Let's say that after collecting two items, we want the player
to be able to defeat monsters within three hits in about 50% of the
battles. How many hit points should the monster have?</p>
<p>One way to answer this question is through sampling. We can use the
following scheme:</p>
<ol class="arabic simple">
<li>Randomly pick a magic item.</li>
<li>Based on the item's bonuses, compute the number of dice that will be
rolled when attacking.</li>
<li>Based on the number of dice that will be rolled, generate a sample
for the damage inflicted over three hits.</li>
<li>Repeat steps 1-3 many times. This will result in an approximation to
the distribution over damage.</li>
</ol>
<p class="rubric" id="implementing-a-distribution-over-damage">Implementing a Distribution Over Damage</p>
<p>The class <code class="docutils literal"><span class="pre">DamageDistribution</span></code> (also in <code class="docutils literal"><span class="pre">rpg.py</span></code>) shows an
implementation of this scheme:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DamageDistribution</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="n">item_dist</span><span class="p">,</span>
                 <span class="n">num_dice_sides</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">num_hits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">rso</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize a distribution over attack damage. This object can</span>
<span class="sd">        sample possible values for the attack damage dealt over</span>
<span class="sd">        `num_hits` hits when the player has `num_items` items, and</span>
<span class="sd">        where attack damage is computed by rolling dice with</span>
<span class="sd">        `num_dice_sides` sides.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        num_items: int</span>
<span class="sd">            The number of items the player has.</span>
<span class="sd">        item_dist: MagicItemDistribution object</span>
<span class="sd">            The distribution over magic items.</span>
<span class="sd">        num_dice_sides: int (default: 12)</span>
<span class="sd">            The number of sides on each die.</span>
<span class="sd">        num_hits: int (default: 1)</span>
<span class="sd">            The number of hits across which we want to calculate damage.</span>
<span class="sd">        rso: numpy RandomState object (default: np.random)</span>
<span class="sd">            The random number generator</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># This is an array of integers corresponding to the sides of a</span>
        <span class="c1"># single die.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dice_sides</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_dice_sides</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Create a multinomial distribution corresponding to one of</span>
        <span class="c1"># these dice.  Each side has equal probabilities.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dice_dist</span> <span class="o">=</span> <span class="n">MultinomialDistribution</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_dice_sides</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_dice_sides</span><span class="p">),</span> <span class="n">rso</span><span class="o">=</span><span class="n">rso</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_hits</span> <span class="o">=</span> <span class="n">num_hits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="n">num_items</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_dist</span> <span class="o">=</span> <span class="n">item_dist</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sample the attack damage.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">            The sampled damage</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># First, we need to randomly generate items (the number of</span>
        <span class="c1"># which was passed into the constructor).</span>
        <span class="n">items</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">item_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)]</span>

        <span class="c1"># Based on the item stats (in particular, strength), compute</span>
        <span class="c1"># the number of dice we get to roll.</span>
        <span class="n">num_dice</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;strength&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">])</span>

        <span class="c1"># Roll the dice and compute the resulting damage.</span>
        <span class="n">dice_rolls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dice_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hits</span> <span class="o">*</span> <span class="n">num_dice</span><span class="p">)</span>
        <span class="n">damage</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dice_sides</span> <span class="o">*</span> <span class="n">dice_rolls</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">damage</span>
</pre></div>
</div>
<p>The constructor takes as arguments the number of sides the dice have,
how many hits we want to compute damage over, how many items the player
has, a distribution over magic items (of type <code class="docutils literal"><span class="pre">MagicItemDistribution</span></code>)
and a random state object. By default, we set <code class="docutils literal"><span class="pre">num_dice_sides</span></code> to 12
because, while it is technically a parameter, it is unlikely to change.
Similarly, we set <code class="docutils literal"><span class="pre">num_hits</span></code> to 1 as a default because a more likely
use case is that we just want to take one sample of the damage for a
single hit.</p>
<p>We then implement the actual sampling logic in <code class="docutils literal"><span class="pre">sample</span></code>. (Note the
structural similarity to <code class="docutils literal"><span class="pre">MagicItemDistribution</span></code>.) First, we generate
a set of possible magic items that the player has. Then, we look at the
strength stat of those items, and from that compute the number of dice
to roll. Finally, we roll the dice (again relying on our trusty
multinomial functions) and compute the damage from that.</p>
<p class="rubric" id="what-happened-to-evaluating-probabilities">What Happened to Evaluating Probabilities?</p>
<p>You may have noticed that we didn't include a <code class="docutils literal"><span class="pre">log_pmf</span></code> or <code class="docutils literal"><span class="pre">pmf</span></code>
function in our <code class="docutils literal"><span class="pre">DamageDistribution</span></code>. This is because we actually do
not know what the PMF should be! This would be the equation:</p>
<p>\[ \sum_{{item}_1, \ldots{}, {item}_m} p(\mathrm{damage} \vert
\mathrm{item}_1,\ldots{},\mathrm{item}_m)p(\mathrm{item}_1)\cdots{}p(\mathrm{item}_m)
\]</p>
<p>What this equation says is that we would need to compute the probability
of every possible damage amount, given every possible set of \(m\)
items. We actually <em>could</em> compute this through brute force, but it
wouldn't be pretty. This is actually a perfect example of a case where
we want to use sampling to approximate the solution to a problem that we
can't compute exactly (or which would be very difficult to compute
exactly). So, rather than having a method for the PMF, we'll show in the
next section how we can approximate the distribution with many samples.</p>
<p class="rubric" id="approximating-the-distribution">Approximating the Distribution</p>
<p>Now we have the machinery to answer our question from earlier: If the
player has two items, and we want the player to be able to defeat the
monster within three hits 50% of the time, how many hit points should
the monster have?</p>
<p>First, we create our distribution object, using the same <code class="docutils literal"><span class="pre">item_dist</span></code>
and <code class="docutils literal"><span class="pre">rso</span></code> that we created earlier:</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">rpg</span> <span class="k">import</span> <span class="n">DamageDistribution</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">damage_dist</span> <span class="o">=</span> <span class="n">DamageDistribution</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">item_dist</span><span class="p">,</span> <span class="n">num_hits</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">rso</span><span class="o">=</span><span class="n">rso</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we can draw a bunch of samples, and compute the 50th percentile (the
damage value that is greater than 50% of the samples):</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">damage_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="mi">100000</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="go">154</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="go">27.0</span>
</pre></div>
</div>
<p>If we were to plot a histogram of how many samples we got for each
amount of damage, it would look something like <a class="reference external" href="#figure-18.1">Figure 18.1</a>.</p>
<div class="center figure"><p><img alt="Figure 18.1 - Damage Distribution" src="chapters/sampler-images/damage_distribution.png" /></p>
</div><p>Figure 18.1 - Damage Distribution</p>
<p>There is a pretty wide range of damage that the player could potentially
inflict, but it has a long tail: the 50th percentile is at 27 points,
meaning that in half the samples, the player inflicted no more than 27
points of damage. Thus, if we wanted to use this criteria for setting
monster difficulty, we would give them 27 hit points.</p>
<p class="rubric" id="summary">Summary</p>
<p>In this chapter, we've seen how to write code for generating samples
from a non-standard probability distribution, and how to compute the
probabilities for those samples as well. In working through this
example, we've covered several design decisions that are applicable in
the general case:</p>
<ol class="arabic simple">
<li>Representing probability distributions using a class, and including
functions both for sampling and for evaluating the PMF (or PDF).</li>
<li>Computing the PMF (or PDF) using logarithms.</li>
<li>Generating samples from a random number generator object to enable
reproducible randomness.</li>
<li>Writing functions whose inputs/outputs are clear and understandable
(e.g., using dictionaries as the output of
<code class="docutils literal"><span class="pre">MagicItemDistribution.sample</span></code>) while still exposing the less clear
but more efficient and purely numeric version of those functions
(e.g., <code class="docutils literal"><span class="pre">MagicItemDistribution._sample_stats</span></code>).</li>
</ol>
<p>Additionally, we've seen how sampling from a probability distribution
can be useful both for producing single random values (e.g., generating
a single magical item after defeating a monster) and for computing
information about a distribution that we would otherwise not know (e.g.,
discovering how much damage a player with two items is likely to deal).
Almost every type of sampling you might encounter falls under one of
these two categories; the differences only have to do with what
distributions you are sampling from. The general structure of the
code—independent of those distributions—remains the same.</p>
<div class="footnotes"><hr class="docutils" />
<ol class="arabic">
<li><div class="first"><div id="fn1"></div></div><p>This chapter assumes some familiarity with statistics and probability
theory.<a class="reference external" href="#fnref1">↩</a></p>
</li>
<li><div class="first"><div id="fn2"></div></div><p>NumPy includes functions to draw samples from many different types of
distributions. For a full list, take a look at the random sampling
module, <code class="docutils literal"><span class="pre">np.random</span></code>.<a class="reference external" href="#fnref2">↩</a></p>
</li>
<li><div class="first"><div id="fn3"></div></div><p>The functions in <code class="docutils literal"><span class="pre">np.random</span></code> actually do rely on a random number
generator that we can control: NumPy's global random number
generator. You can set the global seed with <code class="docutils literal"><span class="pre">np.seed</span></code>. There's a
tradeoff to using the global generator vs. a local <code class="docutils literal"><span class="pre">RandomState</span></code>
object. If you use the global generator, then you don't have to pass
around a <code class="docutils literal"><span class="pre">RandomState</span></code> object everywhere. However, you also run the
risk of depending on some third party code that also uses the global
generator without your knowledge. If you use a local object, then it
is easier to find out whether there is nondeterminism coming from
somewhere other than your own code.<a class="reference external" href="#fnref3">↩</a></p>
</li>
</ol>
</div></div></div></div></div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Learn-Computer-and-Math-again</a></h1>








<h3>导航</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="blockcode-a-visual-programming-toolkit.html">500 Lines or Less | Blockcode: A visual programming toolkit</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>快速搜索</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="转向" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, timger.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="../_sources/chapters/a-rejection-sampler.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>