
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="zh">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>500 Lines or Less | Optical Character Recognition (OCR) &#8212; Learn-Computer-and-Math-again 0.0.1 文档</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="lines-or-less-optical-character-recognition-ocr">
<h1>500 Lines or Less | Optical Character Recognition (OCR)<a class="headerlink" href="#lines-or-less-optical-character-recognition-ocr" title="永久链接至标题">¶</a></h1>
<div class="container"><div class="row"><div class="hero-unit"><p><a href="#id1"><span class="problematic" id="id2">``</span></a>_
.. rubric:: Optical Character Recognition (OCR)</p>
<blockquote>
<div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">name:</th><td class="field-body">optical-character-recognition-ocr</td>
</tr>
</tbody>
</table>
</div></blockquote>
<p class="author rubric" id="marina-samuel">Marina Samuel</p>
</div></div><div class="row"><div id="content" class="span10 offset1"><p class="rubric" id="introduction">Introduction</p>
<p>What if your computer could wash your dishes, do your laundry, cook you
dinner, and clean your home? I think I can safely say that most people
would be happy to get a helping hand! But what would it take for a
computer to be able to perform these tasks in the same way that humans
can?</p>
<p>The famous computer scientist Alan Turing proposed the Turing Test as a
way to identify whether a machine could have intelligence
indistinguishable from that of a human being. The test involves a human
posing questions to two hidden entities, one human, and the other a
machine, and trying to identify which is which. If the interrogator is
unable to identify the machine, then the machine is considered to have
human-level intelligence.</p>
<p>While there is a lot of controversy surrounding whether the Turing Test
is a valid assessment of intelligence, and whether we can build such
intelligent machines, there is no doubt that machines with some degree
of intelligence already exist. There is currently software that helps
robots navigate an office and perform small tasks, or help those
suffering with Alzheimer's. More common examples of Artificial
Intelligence (A.I.) are the way that Google estimates what you’re
looking for when you search for some keywords, or the way that Facebook
decides what to put in your news feed.</p>
<p>One well known application of A.I. is Optical Character Recognition
(OCR). An OCR system is a piece of software that can take images of
handwritten characters as input and interpret them into machine readable
text. While you may not think twice when depositing a handwritten cheque
into a bank machine , there is some interesting work going on in the
background. This chapter will examine a working example of a simple OCR
system that recognizes numerical digits using an Artificial Neural
Network (ANN). But first, let’s establish a bit more context.</p>
<p class="rubric" id="what-is-artificial-intelligence">What is Artificial Intelligence?</p>
<p>&nbsp; While Turing’s definition of intelligence sounds reasonable, at the
end of the day what constitutes intelligence is fundamentally a
philosophical debate. Computer scientists have, however, categorized
certain types of systems and algorithms into branches of AI. Each branch
is used to solve certain sets of problems. These branches include the
following examples, as well as <a class="reference external" href="http://www-formal.stanford.edu/jmc/whatisai/node2.html">many others</a>:</p>
<ul class="simple">
<li>Logical and probabilistic deduction and inference based on some
predefined knowledge of a world. e.g. <a class="reference external" href="http://www.cs.princeton.edu/courses/archive/fall07/cos436/HIDDEN/Knapp/fuzzy004.htm">Fuzzy inference</a> can help a
thermostat decide when to turn on the air conditioning when it
detects that the temperature is hot and the atmosphere is humid</li>
<li>Heuristic search. e.g. Searching can be used to find the best
possible next move in a game of chess by searching all possible moves
and choosing the one that most improves your position</li>
<li>Machine learning (ML) with feedback models. e.g. Pattern-recognition
problems like OCR.</li>
</ul>
<p>In general, ML involves using large data sets to train a system to
identify patterns. The training data sets may be labelled, meaning the
system’s expected outputs are specified for given inputs, or unlabelled
meaning expected outputs are not specified. Algorithms that train
systems with unlabelled data are called <em>unsupervised</em> algorithms and
those that train with labelled data are called <em>supervised</em>. Many ML
algorithms and techniques exist for creating OCR systems, of which ANNs
are one approach.</p>
<p class="rubric" id="artificial-neural-networks">Artificial Neural Networks</p>
<p class="rubric" id="what-are-anns">What Are ANNs?</p>
<p>&nbsp; An ANN is a structure consisting of interconnected nodes that
communicate with one another. The structure and its functionality are
inspired by neural networks found in a biological brain. <a class="reference external" href="http://www.nbb.cornell.edu/neurobio/linster/BioNB420/hebb.pdf">Hebbian
Theory</a> explains how these networks can learn to identify patterns by
physically altering their structure and link strengths. Similarly, a
typical ANN (shown in <a class="reference external" href="#figure-15.1">Figure 15.1</a>) has connections between nodes that
have a weight which is updated as the network learns. The nodes labelled
&quot;+1&quot; are called <em>biases</em>. The leftmost blue column of nodes are <em>input
nodes</em>, the middle column contains <em>hidden nodes</em>, and the rightmost
column contains <em>output nodes</em>. There may be many columns of hidden
nodes, known as <em>hidden layers</em>.</p>
<div class="center figure"><p><img alt="Figure 15.1 - An Artificial Neural Network" src="chapters/ocr-images/ann.png" /></p>
</div><p>Figure 15.1 - An Artificial Neural Network</p>
<p>The values inside all of the circular nodes in <a class="reference external" href="#figure-15.1">Figure 15.1</a> represent
the output of the node. If we call the output of the \(n\)th node from
the top in layer \(L\) as a \(n(L)\) and the connection between the
\(i\)th node in layer \(L\) and the \(j\)th node in layer
\(L+1\) as \(w^{(L)}_ji\), then the output of node \(a^{(2)}_2\)
is:</p>
<p>\[ a^{(2)}_2 = f(w^{(1)}_{21}x_1 + w^{(1)}_{22}x_2 + b^{(1)}_{2})
\]</p>
<p>where \(f(.)\) is known as the <em>activation function</em> and \(b\) is
the <em>bias</em>. An activation function is the decision-maker for what type
of output a node has. A bias is an additional node with a fixed output
of 1 that may be added to an ANN to improve its accuracy. We’ll see more
details on both of these in <cite>Designing a Feedforward ANN
(``neural_network_design.py`</cite>)`_.</p>
<p>This type of network topology is called a <em>feedforward</em> neural network
because there are no cycles in the network. ANNs with nodes whose
outputs feed into their inputs are called recurrent neural networks.
There are many algorithms that can be applied to train feedforward ANNs;
one commonly used algorithm is called <em>backpropagation</em>. The OCR system
we will implement in this chapter will use backpropagation.</p>
<p class="rubric" id="how-do-we-use-anns">How Do We Use ANNs?</p>
<p>Like most other ML approaches, the first step for using backpropagation
is to decide how to transform or reduce our problem into one that can be
solved by an ANN. In other words, how can we manipulate our input data
so we can feed it into the ANN? For the case of our OCR system, we can
use the positions of the pixels for a given digit as input. It is worth
noting that, often times, choosing the input data format is not this
simple. If we were analyzing large images to identify shapes in them,
for instance, we may need to pre-process the image to identify contours
within it. These contours would be the input.</p>
<p>Once we’ve decided on our input data format, what’s next? Since
backpropagation is a supervised algorithm, it will need to be trained
with labelled data, as mentioned in <a class="reference external" href="#sec.ocr.ai">What is Artificial Intelligence?</a>.
Thus, when passing the pixel positions as training input, we must also
pass the associated digit. This means that we must find or gather a
large data set of drawn digits and associated values.</p>
<p>The next step is to partition the data set into a training set and
validation set. The training data is used to run the backpropagation
algorithm to set the weights of the ANN. The validation data is used to
make predictions using the trained network and compute its accuracy. If
we were comparing the performance of backpropagation vs. another
algorithm on our data, we would <a class="reference external" href="http://www-group.slac.stanford.edu/sluo/Lectures/stat_lecture_files/sluo2006lec7.pdf">split the data</a> into 50% for training,
25% for comparing performance of the 2 algorithms (validation set) and
the final 25% for testing accuracy of the chosen algorithm (test set).
Since we’re not comparing algorithms, we can group one of the 25% sets
as part of the training set and use 75% of the data to train the network
and 25% for validating that it was trained well.</p>
<p>The purpose of identifying the accuracy of the ANN is two-fold. First,
it is to avoid the problem of <em>overfitting</em>. Overfitting occurs when the
network has a much higher accuracy on predicting the training set than
the validation set. Overfitting tells us that the chosen training data
does not generalize well enough and needs to be refined. Secondly,
testing the accuracy of several different numbers of hidden layers and
hidden nodes helps in designing the most optimal ANN size. An optimal
ANN size will have enough hidden nodes and layers to make accurate
predictions but also as few nodes/connections as possible to reduce
computational overhead that may slow down training and predictions. Once
the optimal size has been decided and the network has been trained, it’s
ready to make predictions!</p>
<p class="rubric" id="design-decisions-in-a-simple-ocr-system">Design Decisions in a Simple OCR System</p>
<p>&nbsp; In the last few paragraphs we’ve gone over some of the basics of
feedforward ANNs and how to use them. Now it’s time to talk about how we
can build an OCR system.</p>
<p>First off, we must decide what we want our system to be able to do. To
keep things simple, let’s allow users to draw a single digit and be able
to train the OCR system with that drawn digit or to request that the
system predict what the drawn digit is. While an OCR system could run
locally on a single machine, having a client-server setup gives much
more flexibility. It makes crowd-sourced training of an ANN possible and
allows powerful servers to handle intensive computations.</p>
<p>Our OCR system will consist of 5 main components, divided into 5 files.
There will be:</p>
<ul class="simple">
<li>a client (<code class="docutils literal"><span class="pre">ocr.js</span></code>)</li>
<li>a server (<code class="docutils literal"><span class="pre">server.py</span></code>)</li>
<li>a simple user interface (<code class="docutils literal"><span class="pre">ocr.html</span></code>)</li>
<li>an ANN trained via backpropagation (<code class="docutils literal"><span class="pre">ocr.py</span></code>)</li>
<li>an ANN design script (<code class="docutils literal"><span class="pre">neural_network_design.py</span></code>)</li>
</ul>
<p>The user interface will be simple: a canvas to draw digits on and
buttons to either train the ANN or request a prediction. The client will
gather the drawn digit, translate it into an array, and pass it to the
server to be processed either as a training sample or as a prediction
request. The server will simply route the training or prediction request
by making API calls to the ANN module. The ANN module will train the
network with an existing data set on its first initialization. It will
then save the ANN weights to a file and re-load them on subsequent
startups. This module is where the core of training and prediction logic
happens. Finally, the design script is for experimenting with different
hidden node counts and deciding what works best. Together, these pieces
give us a very simplistic, but functional OCR system.</p>
<p>Now that we've thought about how the system will work at a high level,
it's time to put the concepts into code!</p>
<p class="rubric" id="a-simple-interface-ocr-html">A Simple Interface (<code class="docutils literal"><span class="pre">ocr.html</span></code>)</p>
<p>As mentioned earlier, the first step is to gather data for training the
network. We could upload a sequence of hand-written digits to the
server, but that would be awkward. Instead, we could have users actually
handwrite the digits on the page using an HTML canvas. We could then
give them a couple of options to either train or test the network, where
training the network also involves specifying what digit was drawn. This
way it is possible to easily outsource the data collection by pointing
people to a website to receive their input. Here’s some HTML to get us
started.</p>
<div class="code html highlight-default"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">html</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">head</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">script</span> <span class="n">src</span><span class="o">=</span><span class="s2">&quot;ocr.js&quot;</span><span class="o">&gt;&lt;/</span><span class="n">script</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">link</span> <span class="n">rel</span><span class="o">=</span><span class="s2">&quot;stylesheet&quot;</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;text/css&quot;</span> <span class="n">href</span><span class="o">=</span><span class="s2">&quot;ocr.css&quot;</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="n">head</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">body</span> <span class="n">onload</span><span class="o">=</span><span class="s2">&quot;ocrDemo.onLoadFunction()&quot;</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">div</span> <span class="nb">id</span><span class="o">=</span><span class="s2">&quot;main-container&quot;</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;text-align: center;&quot;</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="n">h1</span><span class="o">&gt;</span><span class="n">OCR</span> <span class="n">Demo</span><span class="o">&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="n">canvas</span> <span class="nb">id</span><span class="o">=</span><span class="s2">&quot;canvas&quot;</span> <span class="n">width</span><span class="o">=</span><span class="s2">&quot;200&quot;</span> <span class="n">height</span><span class="o">=</span><span class="s2">&quot;200&quot;</span><span class="o">&gt;&lt;/</span><span class="n">canvas</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="n">form</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="o">&gt;</span>
            <span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">Digit</span><span class="p">:</span> <span class="o">&lt;</span><span class="nb">input</span> <span class="nb">id</span><span class="o">=</span><span class="s2">&quot;digit&quot;</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="o">&gt;</span> <span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
            <span class="o">&lt;</span><span class="nb">input</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;button&quot;</span> <span class="n">value</span><span class="o">=</span><span class="s2">&quot;Train&quot;</span> <span class="n">onclick</span><span class="o">=</span><span class="s2">&quot;ocrDemo.train()&quot;</span><span class="o">&gt;</span>
            <span class="o">&lt;</span><span class="nb">input</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;button&quot;</span> <span class="n">value</span><span class="o">=</span><span class="s2">&quot;Test&quot;</span> <span class="n">onclick</span><span class="o">=</span><span class="s2">&quot;ocrDemo.test()&quot;</span><span class="o">&gt;</span>
            <span class="o">&lt;</span><span class="nb">input</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;button&quot;</span> <span class="n">value</span><span class="o">=</span><span class="s2">&quot;Reset&quot;</span> <span class="n">onclick</span><span class="o">=</span><span class="s2">&quot;ocrDemo.resetCanvas();&quot;</span><span class="o">/&gt;</span>
        <span class="o">&lt;/</span><span class="n">form</span><span class="o">&gt;</span>
    <span class="o">&lt;/</span><span class="n">div</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="n">body</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="n">html</span><span class="o">&gt;</span>
</pre></div>
</div>
<p class="rubric" id="an-ocr-client-ocr-js">An OCR Client (<code class="docutils literal"><span class="pre">ocr.js</span></code>)</p>
<p>Since a single pixel on an HTML canvas might be hard to see, we can
represent a single pixel for the ANN input as a square of 10x10 real
pixels. Thus the real canvas is 200x200 pixels and it is represented by
a 20x20 canvas from the perspective of the ANN. The variables below will
help us keep track of these measurements.</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">var</span> <span class="n">ocrDemo</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">CANVAS_WIDTH</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
    <span class="n">TRANSLATED_WIDTH</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">PIXEL_WIDTH</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="o">//</span> <span class="n">TRANSLATED_WIDTH</span> <span class="o">=</span> <span class="n">CANVAS_WIDTH</span> <span class="o">/</span> <span class="n">PIXEL_WIDTH</span>
</pre></div>
</div>
<p>We can then outline the pixels in the new representation so they are
easier to see. Here we have a blue grid generated by <code class="docutils literal"><span class="pre">drawGrid()</span></code>.</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">drawGrid</span><span class="p">:</span> <span class="n">function</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">var</span> <span class="n">x</span> <span class="o">=</span> <span class="n">this</span><span class="o">.</span><span class="n">PIXEL_WIDTH</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">this</span><span class="o">.</span><span class="n">PIXEL_WIDTH</span><span class="p">;</span>
             <span class="n">x</span> <span class="o">&lt;</span> <span class="n">this</span><span class="o">.</span><span class="n">CANVAS_WIDTH</span><span class="p">;</span> <span class="n">x</span> <span class="o">+=</span> <span class="n">this</span><span class="o">.</span><span class="n">PIXEL_WIDTH</span><span class="p">,</span>
             <span class="n">y</span> <span class="o">+=</span> <span class="n">this</span><span class="o">.</span><span class="n">PIXEL_WIDTH</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">strokeStyle</span> <span class="o">=</span> <span class="n">this</span><span class="o">.</span><span class="n">BLUE</span><span class="p">;</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">beginPath</span><span class="p">();</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">moveTo</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">lineTo</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">this</span><span class="o">.</span><span class="n">CANVAS_WIDTH</span><span class="p">);</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">stroke</span><span class="p">();</span>

        <span class="n">ctx</span><span class="o">.</span><span class="n">beginPath</span><span class="p">();</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">moveTo</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">lineTo</span><span class="p">(</span><span class="n">this</span><span class="o">.</span><span class="n">CANVAS_WIDTH</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">stroke</span><span class="p">();</span>
    <span class="p">}</span>
<span class="p">},</span>
</pre></div>
</div>
<p>We also need to store the data drawn on the grid in a form that can be
sent to the server. For simplicity, we can have an array called <code class="docutils literal"><span class="pre">data</span></code>
which labels an uncoloured, black pixel as <code class="docutils literal"><span class="pre">0</span></code> and a coloured white
pixel as <code class="docutils literal"><span class="pre">1</span></code>. We also need some mouse listeners on the canvas so we
know when to call <code class="docutils literal"><span class="pre">fillSquare()</span></code> to colour a pixel white while a user
is drawing a digit. These listeners should keep track of whether we are
in a drawing state and then call <code class="docutils literal"><span class="pre">fillSquare()</span></code> to do some simple math
and decide which pixels need to be filled in.</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span>onMouseMove: function(e, ctx, canvas) {
    if (!canvas.isDrawing) {
        return;
    }
    this.fillSquare(ctx,
        e.clientX - canvas.offsetLeft, e.clientY - canvas.offsetTop);
},

onMouseDown: function(e, ctx, canvas) {
    canvas.isDrawing = true;
    this.fillSquare(ctx,
        e.clientX - canvas.offsetLeft, e.clientY - canvas.offsetTop);
},

onMouseUp: function(e) {
    canvas.isDrawing = false;
},

fillSquare: function(ctx, x, y) {
    var xPixel = Math.floor(x / this.PIXEL_WIDTH);
    var yPixel = Math.floor(y / this.PIXEL_WIDTH);
    this.data[((xPixel - 1)  * this.TRANSLATED_WIDTH + yPixel) - 1] = 1;

    ctx.fillStyle = &#39;#ffffff&#39;;
    ctx.fillRect(xPixel * this.PIXEL_WIDTH, yPixel * this.PIXEL_WIDTH,
        this.PIXEL_WIDTH, this.PIXEL_WIDTH);
},
</pre></div>
</div>
<p>Now we’re getting closer to the juicy stuff! We need a function that
prepares training data to be sent to the server. Here we have a
relatively straight forward <code class="docutils literal"><span class="pre">train()</span></code> function that does some error
checking on the data to be sent, adds it to <code class="docutils literal"><span class="pre">trainArray</span></code> and sends it
off by calling <code class="docutils literal"><span class="pre">sendData()</span></code>.</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span>train: function() {
    var digitVal = document.getElementById(&quot;digit&quot;).value;
    if (!digitVal || this.data.indexOf(1) &lt; 0) {
        alert(&quot;Please type and draw a digit value in order to train the network&quot;);
        return;
    }
    this.trainArray.push({&quot;y0&quot;: this.data, &quot;label&quot;: parseInt(digitVal)});
    this.trainingRequestCount++;

    // Time to send a training batch to the server.
    if (this.trainingRequestCount == this.BATCH_SIZE) {
        alert(&quot;Sending training data to server...&quot;);
        var json = {
            trainArray: this.trainArray,
            train: true
        };

        this.sendData(json);
        this.trainingRequestCount = 0;
        this.trainArray = [];
    }
},
</pre></div>
</div>
<p>An interesting design worth noting here is the use of
<code class="docutils literal"><span class="pre">trainingRequestCount</span></code>, <code class="docutils literal"><span class="pre">trainArray</span></code>, and <code class="docutils literal"><span class="pre">BATCH_SIZE</span></code>. What’s
happening here is that <code class="docutils literal"><span class="pre">BATCH_SIZE</span></code> is some pre-defined constant for
how much training data a client will keep track of before it sends a
batched request to the server to be processed by the OCR. The main
reason to batch requests is to avoid overwhelming the server with many
requests at once. If many clients exist (e.g. many users are on the
<code class="docutils literal"><span class="pre">ocr.html</span></code> page training the system), or if another layer existed in
the client that takes scanned drawn digits and translated them to pixels
to train the network, a <code class="docutils literal"><span class="pre">BATCH_SIZE</span></code> of 1 would result in many,
unnecessary requests. This approach is good because it gives more
flexibility to the client, however, in practice, batching should also
take place on the server, when needed. A denial of service (DoS) attack
could occur in which a malicious client purposely sends many requests to
the server to overwhelm it so that it breaks down.</p>
<p>We will also need a <code class="docutils literal"><span class="pre">test()</span></code> function. Similar to <code class="docutils literal"><span class="pre">train()</span></code>, it
should do a simple check on the validity of the data and send it off.
For <code class="docutils literal"><span class="pre">test()</span></code>, however, no batching occurs since users should be able
to request a prediction and get immediate results.</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">test</span><span class="p">:</span> <span class="n">function</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">this</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">indexOf</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">alert</span><span class="p">(</span><span class="s2">&quot;Please draw a digit in order to test the network&quot;</span><span class="p">);</span>
        <span class="k">return</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">var</span> <span class="n">json</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">this</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
        <span class="n">predict</span><span class="p">:</span> <span class="n">true</span>
    <span class="p">};</span>
    <span class="n">this</span><span class="o">.</span><span class="n">sendData</span><span class="p">(</span><span class="n">json</span><span class="p">);</span>
<span class="p">},</span>
</pre></div>
</div>
<p>Finally, we will need some functions to make an HTTP POST request,
receive a response, and handle any potential errors along the way.</p>
<div class="code javascript highlight-default"><div class="highlight"><pre><span></span><span class="n">receiveResponse</span><span class="p">:</span> <span class="n">function</span><span class="p">(</span><span class="n">xmlHttp</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">xmlHttp</span><span class="o">.</span><span class="n">status</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">alert</span><span class="p">(</span><span class="s2">&quot;Server returned status &quot;</span> <span class="o">+</span> <span class="n">xmlHttp</span><span class="o">.</span><span class="n">status</span><span class="p">);</span>
        <span class="k">return</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">var</span> <span class="n">responseJSON</span> <span class="o">=</span> <span class="n">JSON</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">xmlHttp</span><span class="o">.</span><span class="n">responseText</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">xmlHttp</span><span class="o">.</span><span class="n">responseText</span> <span class="o">&amp;&amp;</span> <span class="n">responseJSON</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">alert</span><span class="p">(</span><span class="s2">&quot;The neural network predicts you wrote a </span><span class="se">\&#39;</span><span class="s2">&quot;</span>
               <span class="o">+</span> <span class="n">responseJSON</span><span class="o">.</span><span class="n">result</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\&#39;</span><span class="s1">&#39;</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">},</span>

<span class="n">onError</span><span class="p">:</span> <span class="n">function</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">alert</span><span class="p">(</span><span class="s2">&quot;Error occurred while connecting to server: &quot;</span> <span class="o">+</span> <span class="n">e</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">statusText</span><span class="p">);</span>
<span class="p">},</span>

<span class="n">sendData</span><span class="p">:</span> <span class="n">function</span><span class="p">(</span><span class="n">json</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">var</span> <span class="n">xmlHttp</span> <span class="o">=</span> <span class="n">new</span> <span class="n">XMLHttpRequest</span><span class="p">();</span>
    <span class="n">xmlHttp</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;POST&#39;</span><span class="p">,</span> <span class="n">this</span><span class="o">.</span><span class="n">HOST</span> <span class="o">+</span> <span class="s2">&quot;:&quot;</span> <span class="o">+</span> <span class="n">this</span><span class="o">.</span><span class="n">PORT</span><span class="p">,</span> <span class="n">false</span><span class="p">);</span>
    <span class="n">xmlHttp</span><span class="o">.</span><span class="n">onload</span> <span class="o">=</span> <span class="n">function</span><span class="p">()</span> <span class="p">{</span> <span class="n">this</span><span class="o">.</span><span class="n">receiveResponse</span><span class="p">(</span><span class="n">xmlHttp</span><span class="p">);</span> <span class="p">}</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">this</span><span class="p">);</span>
    <span class="n">xmlHttp</span><span class="o">.</span><span class="n">onerror</span> <span class="o">=</span> <span class="n">function</span><span class="p">()</span> <span class="p">{</span> <span class="n">this</span><span class="o">.</span><span class="n">onError</span><span class="p">(</span><span class="n">xmlHttp</span><span class="p">)</span> <span class="p">}</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">this</span><span class="p">);</span>
    <span class="n">var</span> <span class="n">msg</span> <span class="o">=</span> <span class="n">JSON</span><span class="o">.</span><span class="n">stringify</span><span class="p">(</span><span class="n">json</span><span class="p">);</span>
    <span class="n">xmlHttp</span><span class="o">.</span><span class="n">setRequestHeader</span><span class="p">(</span><span class="s1">&#39;Content-length&#39;</span><span class="p">,</span> <span class="n">msg</span><span class="o">.</span><span class="n">length</span><span class="p">);</span>
    <span class="n">xmlHttp</span><span class="o">.</span><span class="n">setRequestHeader</span><span class="p">(</span><span class="s2">&quot;Connection&quot;</span><span class="p">,</span> <span class="s2">&quot;close&quot;</span><span class="p">);</span>
    <span class="n">xmlHttp</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">msg</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p class="rubric" id="a-server-server-py">A Server (<code class="docutils literal"><span class="pre">server.py</span></code>)</p>
<p>Despite being a small server that simply relays information, we still
need to consider how to receive and handle the HTTP requests. First we
need to decide what kind of HTTP request to use. In the last section,
the client is using POST, but why did we decide on this? Since data is
being sent to the server, a PUT or POST request makes the most sense. We
only need to send a json body and no URL parameters. So in theory, a GET
request could have worked as well but would not make sense semantically.
The choice between PUT and POST, however, is a long, on-going debate
among programmers; KNPLabs summarizes the issues <a class="reference external" href="https://knpuniversity.com/screencast/rest/put-versus-post">with humour</a>.</p>
<p>Another consideration is whether to send the &quot;train&quot; vs. &quot;predict&quot;
requests to different endpoints (e.g. <code class="docutils literal"><span class="pre">http://localhost/train</span></code> and
<code class="docutils literal"><span class="pre">http://localhost/predict</span></code>) or the same endpoint which then processes
the data separately. In this case, we can go with the latter approach
since the difference between what is done with the data in each case is
minor enough to fit into a short if statement. In practice, it would be
better to have these as separate endpoints if the server were to do any
more detailed processing for each request type. This decision, in turn
impacted what server error codes were used when. For example, a 400 &quot;Bad
Request&quot; error is sent when neither &quot;train&quot; or &quot;predict&quot; is specified in
the payload. If separate endpoints were used instead, this would not be
an issue. The processing done in the background by the OCR system may
fail for any reason and if it's not handled correctly within the server,
a 500 &quot;Internal Server Error&quot; is sent. Again, if the endpoints were
separated, there would have been more room to go into detail to send
more appropriate errors. For example, identifying that an internal
server error was actually caused by a bad request.</p>
<p>Finally, we need to decide when and where to initialize the OCR system.
A good approach would be to initialize it within <code class="docutils literal"><span class="pre">server.py</span></code> but
before the server is started. This is because on first run, the OCR
system needs to train the network on some pre-existing data the first
time it starts and this may take a few minutes. If the server started
before this processing was complete, any requests to train or predict
would throw an exception since the OCR object would not yet have been
initialized, given the current implementation. Another possible
implementation could create some inaccurate initial ANN to be used for
the first few queries while the new ANN is asynchronously trained in the
background. This alternative approach does allow the ANN to be used
immediately, but the implementation is more complex and it would only
save on time on server startup if the servers are reset. This type of
implementation would be more beneficial for an OCR service that requires
high availability.</p>
<p>Here we have the majority of our server code in one short function that
handles POST requests.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">do_POST</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">response_code</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="n">response</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="n">var_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;Content-Length&#39;</span><span class="p">))</span>
    <span class="n">content</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">rfile</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">var_len</span><span class="p">);</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">content</span><span class="p">);</span>

    <span class="k">if</span> <span class="n">payload</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">payload</span><span class="p">[</span><span class="s1">&#39;trainArray&#39;</span><span class="p">])</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">payload</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span><span class="s2">&quot;test&quot;</span><span class="p">,</span>
                <span class="s2">&quot;result&quot;</span><span class="p">:</span><span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">payload</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]))</span>
            <span class="p">}</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">response_code</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">response_code</span> <span class="o">=</span> <span class="mi">400</span>

    <span class="n">s</span><span class="o">.</span><span class="n">send_response</span><span class="p">(</span><span class="n">response_code</span><span class="p">)</span>
    <span class="n">s</span><span class="o">.</span><span class="n">send_header</span><span class="p">(</span><span class="s2">&quot;Content-type&quot;</span><span class="p">,</span> <span class="s2">&quot;application/json&quot;</span><span class="p">)</span>
    <span class="n">s</span><span class="o">.</span><span class="n">send_header</span><span class="p">(</span><span class="s2">&quot;Access-Control-Allow-Origin&quot;</span><span class="p">,</span> <span class="s2">&quot;*&quot;</span><span class="p">)</span>
    <span class="n">s</span><span class="o">.</span><span class="n">end_headers</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">response</span><span class="p">:</span>
        <span class="n">s</span><span class="o">.</span><span class="n">wfile</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
<p class="rubric" id="designing-a-feedforward-ann-neural-network-design-py">Designing a Feedforward ANN (<code class="docutils literal"><span class="pre">neural_network_design.py</span></code>)</p>
<p>&nbsp; When designing a feedforward ANN, there are a few factors we must
consider. The first is what activation function to use. We mentioned
activation functions earlier as the decision-maker for a node’s output.
The type of the decision an activation function makes will help us
decide which one to use. In our case, we will be designing an ANN that
outputs a value between 0 and 1 for each digit (0-9). Values closer to 1
would mean the ANN predicts this is the drawn digit and values closer to
0 would mean it’s predicted to not be the drawn digit. Thus, we want an
activation function that would have outputs either close to 0 or close
to 1. We also need a function that is differentiable because we will
need the derivative for our backpropagation computation. A commonly used
function in this case is the sigmoid because it satisfies both these
constraints. StatSoft provides a <a class="reference external" href="http://www.fmi.uni-sofia.bg/fmi/statist/education/textbook/eng/glosa.html">nice list</a> of common activation
functions and their properties.</p>
<p>A second factor to consider is whether we want to include biases. We've
mentioned biases a couple of times before but haven't really talked
about what they are or why we use them. Let's try to understand this by
going back to how the output of a node is computed in <a class="reference external" href="#figure-15.1">Figure 15.1</a>.
Suppose we had a single input node and a single output node, our output
formula would be \(y = f(wx)\), where \(y\) is the output, \(f()\)
is the activation function, \(w\) is the weight for the link between
the nodes, and \(x\) is the variable input for the node. The bias is
essentially a node whose output is always \(1\). This would change the
output formula to \(y = f(wx + b)\) where \(b\) is the weight of the
connection between the bias node and the next node. If we consider
\(w\) and \(b\) as constants and \(x\) as a variable, then adding
a bias adds a constant to our linear function input to \(f(.)\).</p>
<p>Adding the bias therefore allows for a shift in the \(y\)-intercept
and in general gives more flexibility for the output of a node. It's
often good practice to include biases, especially for ANNs with a small
number of inputs and outputs. Biases allow for more flexibility in the
output of the ANN and thus provide the ANN with more room for accuracy.
Without biases, we’re less likely to make correct predictions with our
ANN or would need more hidden nodes to make more accurate predictions.</p>
<p>Other factors to consider are the number of hidden layers and the number
of hidden nodes per layer. For larger ANNs with many inputs and outputs,
these numbers are decided by trying different values and testing the
network's performance. In this case, the performance is measured by
training an ANN of a given size and seeing what percentage of the
validation set is classified correctly. In most cases, a single hidden
layer is sufficient for decent performance, so we only experiment with
the number of hidden nodes here.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># Try various number of hidden nodes and see what performs best</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
    <span class="n">nn</span> <span class="o">=</span> <span class="n">OCRNeuralNetwork</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">data_matrix</span><span class="p">,</span> <span class="n">data_labels</span><span class="p">,</span> <span class="n">train_indices</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">performance</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">test</span><span class="p">(</span><span class="n">data_matrix</span><span class="p">,</span> <span class="n">data_labels</span><span class="p">,</span> <span class="n">test_indices</span><span class="p">,</span> <span class="n">nn</span><span class="p">))</span>
    <span class="nb">print</span> <span class="s2">&quot;</span><span class="si">{i}</span><span class="s2"> Hidden Nodes: </span><span class="si">{val}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="n">performance</span><span class="p">)</span>
</pre></div>
</div>
<p>Here we initialize an ANN with between 5 to 50 hidden nodes in
increments of 5. We then call the <code class="docutils literal"><span class="pre">test()</span></code> function.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">data_matrix</span><span class="p">,</span> <span class="n">data_labels</span><span class="p">,</span> <span class="n">test_indices</span><span class="p">,</span> <span class="n">nn</span><span class="p">):</span>
    <span class="n">avg_sum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">correct_guess_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">test_indices</span><span class="p">:</span>
            <span class="n">test</span> <span class="o">=</span> <span class="n">data_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">data_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">prediction</span><span class="p">:</span>
                <span class="n">correct_guess_count</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">avg_sum</span> <span class="o">+=</span> <span class="p">(</span><span class="n">correct_guess_count</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_indices</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">avg_sum</span> <span class="o">/</span> <span class="mi">100</span>
</pre></div>
</div>
<p>The inner loop is counting the number of correct classifications which
are then divided by the number of attempted classifications at the end.
This gives a ratio or percentage accuracy for the ANN. Since each time
an ANN is trained, its weights may be slightly different, we repeat this
process 100 times in the outer loop so we can take an average of this
particular ANN configuration's accuracy. In our case, a sample run of
<code class="docutils literal"><span class="pre">neural_network_design.py</span></code> looks like the following:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">PERFORMANCE</span>
<span class="o">-----------</span>
<span class="mi">5</span> <span class="n">Hidden</span> <span class="n">Nodes</span><span class="p">:</span> <span class="mf">0.7792</span>
<span class="mi">10</span> <span class="n">Hidden</span> <span class="n">Nodes</span><span class="p">:</span> <span class="mf">0.8704</span>
<span class="mi">15</span> <span class="n">Hidden</span> <span class="n">Nodes</span><span class="p">:</span> <span class="mf">0.8808</span>
<span class="mi">20</span> <span class="n">Hidden</span> <span class="n">Nodes</span><span class="p">:</span> <span class="mf">0.8864</span>
<span class="mi">25</span> <span class="n">Hidden</span> <span class="n">Nodes</span><span class="p">:</span> <span class="mf">0.8808</span>
<span class="mi">30</span> <span class="n">Hidden</span> <span class="n">Nodes</span><span class="p">:</span> <span class="mf">0.888</span>
<span class="mi">35</span> <span class="n">Hidden</span> <span class="n">Nodes</span><span class="p">:</span> <span class="mf">0.8904</span>
<span class="mi">40</span> <span class="n">Hidden</span> <span class="n">Nodes</span><span class="p">:</span> <span class="mf">0.8896</span>
<span class="mi">45</span> <span class="n">Hidden</span> <span class="n">Nodes</span><span class="p">:</span> <span class="mf">0.8928</span>
</pre></div>
</div>
<p>From this output we can conclude that 15 hidden nodes would be most
optimal. Adding 5 nodes from 10 to 15 gets us ~1% more accuracy, whereas
improving the accuracy by another 1% would require adding another 20
nodes. Increasing the hidden node count also increases computational
overhead. So it would take networks with more hidden nodes longer to be
trained and to make predictions. Thus we choose to use the last hidden
node count that resulted in a dramatic increase in accuracy. Of course,
it’s possible when designing an ANN that computational overhead is no
problem and it's top priority to have the most accurate ANN possible. In
that case it would be better to choose 45 hidden nodes instead of 15.</p>
<p class="rubric" id="core-ocr-functionality">Core OCR Functionality</p>
<p>In this section we’ll talk about how the actual training occurs via
backpropagation, how we can use the network to make predictions, and
other key design decisions for core functionality.</p>
<p class="rubric" id="training-via-backpropagation-ocr-py">Training via Backpropagation (<code class="docutils literal"><span class="pre">ocr.py</span></code>)</p>
<p>We use the backpropagation algorithm to train our ANN. It consists of 4
main steps that are repeated for every sample in the training set,
updating the ANN weights each time.</p>
<p>First, we initialize the weights to small (between -1 and 1) random
values. In our case, we initialize them to values between -0.06 and 0.06
and store them in matrices <code class="docutils literal"><span class="pre">theta1</span></code>, <code class="docutils literal"><span class="pre">theta2</span></code>, <code class="docutils literal"><span class="pre">input_layer_bias</span></code>,
and <code class="docutils literal"><span class="pre">hidden_layer_bias</span></code>. Since every node in a layer links to every
node in the next layer we can create a matrix that has m rows and n
columns where n is the number of nodes in one layer and m is the number
of nodes in the adjacent layer. This matrix would represent all the
weights for the links between these two layers. Here theta1 has 400
columns for our 20x20 pixel inputs and <code class="docutils literal"><span class="pre">num_hidden_nodes</span></code> rows.
Likewise, <code class="docutils literal"><span class="pre">theta2</span></code> represents the links between the hidden layer and
output layer. It has <code class="docutils literal"><span class="pre">num_hidden_nodes</span></code> columns and <code class="docutils literal"><span class="pre">NUM_DIGITS</span></code>
(<code class="docutils literal"><span class="pre">10</span></code>) rows. The other two vectors (1 row), <code class="docutils literal"><span class="pre">input_layer_bias</span></code> and
<code class="docutils literal"><span class="pre">hidden_layer_bias</span></code> represent the biases.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_rand_initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size_in</span><span class="p">,</span> <span class="n">size_out</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[((</span><span class="n">x</span> <span class="o">*</span> <span class="mf">0.12</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.06</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size_out</span><span class="p">,</span> <span class="n">size_in</span><span class="p">)]</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">theta1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rand_initialize_weights</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="n">num_hidden_nodes</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">theta2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rand_initialize_weights</span><span class="p">(</span><span class="n">num_hidden_nodes</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">input_layer_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rand_initialize_weights</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span>
                                                      <span class="n">num_hidden_nodes</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rand_initialize_weights</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>The second step is <em>forward propagation</em>, which is essentially computing
the node outputs as described in <a class="reference external" href="#sec.ocr.ann">What Are ANNs?</a>, layer by layer
starting from the input nodes. Here, <code class="docutils literal"><span class="pre">y0</span></code> is an array of size 400 with
the inputs we wish to use to train the ANN. We multiply <code class="docutils literal"><span class="pre">theta1</span></code> by
<code class="docutils literal"><span class="pre">y0</span></code> transposed so that we have two matrices with sizes
<code class="docutils literal"><span class="pre">(num_hidden_nodes</span> <span class="pre">x</span> <span class="pre">400)</span> <span class="pre">*</span> <span class="pre">(400</span> <span class="pre">x</span> <span class="pre">1)</span></code> and have a resulting vector of
outputs for the hidden layer of size num_hidden_nodes. We then add the
bias vector and apply the vectorized sigmoid activation function to this
output vector, giving us <code class="docutils literal"><span class="pre">y1</span></code>. <code class="docutils literal"><span class="pre">y1</span></code> is the output vector of our
hidden layer. The same process is repeated again to compute <code class="docutils literal"><span class="pre">y2</span></code> for
the output nodes. <code class="docutils literal"><span class="pre">y2</span></code> is now our output layer vector with values
representing the likelihood that their index is the drawn number. For
example if someone draws an 8, the value of <code class="docutils literal"><span class="pre">y2</span></code> at the 8th index will
be the largest if the ANN has made the correct prediction. However, 6
may have a higher likelihood than 1 of being the drawn digit since it
looks more similar to 8 and is more likely to use up the same pixels to
be drawn as the 8. <code class="docutils literal"><span class="pre">y2</span></code> becomes more accurate with each additional
drawn digit the ANN is trained with.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># The sigmoid activation function. Operates on scalars.</span>
<span class="k">def</span> <span class="nf">_sigmoid_scalar</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">e</span> <span class="o">**</span> <span class="o">-</span><span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">y1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;y0&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">sum1</span> <span class="o">=</span>  <span class="n">y1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layer_bias</span><span class="p">)</span> <span class="c1"># Add the bias</span>
<span class="n">y1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">sum1</span><span class="p">)</span>

<span class="n">y2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta2</span><span class="p">),</span> <span class="n">y1</span><span class="p">)</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">y2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_bias</span><span class="p">)</span> <span class="c1"># Add the bias</span>
<span class="n">y2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y2</span><span class="p">)</span>
</pre></div>
</div>
<p>The third step is <em>back propagation</em>, which involves computing the
errors at the output nodes then at every intermediate layer back towards
the input. Here we start by creating an expected output vector,
<code class="docutils literal"><span class="pre">actual_vals</span></code>, with a <code class="docutils literal"><span class="pre">1</span></code> at the index of the digit that represents
the value of the drawn digit and <code class="docutils literal"><span class="pre">0</span></code>s otherwise. The vector of
errors at the output nodes, <code class="docutils literal"><span class="pre">output_errors</span></code>, is computed by
subtracting the actual output vector, <code class="docutils literal"><span class="pre">y2</span></code>, from <code class="docutils literal"><span class="pre">actual_vals</span></code>. For
every hidden layer afterwards, we compute two components. First, we have
the next layer’s transposed weight matrix multiplied by its output
errors. Then we have the derivative of the activation function applied
to the previous layer. We then perform an element-wise multiplication on
these two components, giving a vector of errors for a hidden layer. Here
we call this <code class="docutils literal"><span class="pre">hidden_errors</span></code>.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">actual_vals</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>
<span class="n">actual_vals</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">output_errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="n">actual_vals</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="n">y2</span><span class="p">)</span>
<span class="n">hidden_errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta2</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">output_errors</span><span class="p">),</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_prime</span><span class="p">(</span><span class="n">sum1</span><span class="p">))</span>
</pre></div>
</div>
<p>Weight updates that adjust the ANN weights based on the errors computed
earlier. Weights are updated at each layer via matrix multiplication.
The error matrix at each layer is multiplied by the output matrix of the
previous layer. This product is then multiplied by a scalar called the
learning rate and added to the weight matrix. The learning rate is a
value between 0 and 1 that influences the speed and accuracy of learning
in the ANN. Larger learning rate values will generate an ANN that learns
quickly but is less accurate, while smaller values will will generate an
ANN that learns slower but is more accurate. In our case, we have a
relatively small value for learning rate, 0.1. This works well since we
do not need the ANN to be immediately trained in order for a user to
continue making train or predict requests. Biases are updated by simply
multiplying the learning rate by the layer’s error vector.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">theta1</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LEARNING_RATE</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="n">hidden_errors</span><span class="p">),</span>
                                           <span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;y0&#39;</span><span class="p">]))</span>
<span class="bp">self</span><span class="o">.</span><span class="n">theta2</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LEARNING_RATE</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="n">output_errors</span><span class="p">),</span>
                                           <span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="n">y1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_bias</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LEARNING_RATE</span> <span class="o">*</span> <span class="n">output_errors</span>
<span class="bp">self</span><span class="o">.</span><span class="n">input_layer_bias</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LEARNING_RATE</span> <span class="o">*</span> <span class="n">hidden_errors</span>
</pre></div>
</div>
<p class="rubric" id="testing-a-trained-network-ocr-py">Testing a Trained Network (<code class="docutils literal"><span class="pre">ocr.py</span></code>)</p>
<p>Once an ANN has been trained via backpropagation, it is fairly
straightforward to use it for making predictions. As we can see here, we
start by computing the output of the ANN, <code class="docutils literal"><span class="pre">y2</span></code>, exactly the way we did
in step 2 of backpropagation. Then we look for the index in the vector
with the maximum value. This index is the digit predicted by the ANN.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test</span><span class="p">):</span>
    <span class="n">y1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="n">test</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">y1</span> <span class="o">=</span>  <span class="n">y1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">mat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layer_bias</span><span class="p">)</span> <span class="c1"># Add the bias</span>
    <span class="n">y1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y1</span><span class="p">)</span>

    <span class="n">y2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta2</span><span class="p">),</span> <span class="n">y1</span><span class="p">)</span>
    <span class="n">y2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">y2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_bias</span><span class="p">)</span> <span class="c1"># Add the bias</span>
    <span class="n">y2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y2</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="n">y2</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">results</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">results</span><span class="p">))</span>
</pre></div>
</div>
<p class="rubric" id="other-design-decisions-ocr-py">Other Design Decisions (<code class="docutils literal"><span class="pre">ocr.py</span></code>)</p>
<p>Many resources are available online that go into greater detail on the
implementation of backpropagation. One good resource is from a <a class="reference external" href="http://www.willamette.edu/~gorr/classes/cs449/backprop.html">course
by the University of Willamette</a>. It goes over the steps of
backpropagation and then explains how it can be translated into matrix
form. While the amount of computation using matrices is the same as
using loops, the benefit is that the code is simpler and easier to read
with fewer nested loops. As we can see, the entire training process is
written in under 25 lines of code using matrix algebra.</p>
<p>As mentioned in the introduction of <a class="reference external" href="#sec.ocr.decisions">Design Decisions in a Simple OCR
System</a>, persisting the weights of the ANN means we do not lose the
progress made in training it when the server is shut down or abruptly
goes down for any reason. We persist the weights by writing them as JSON
to a file. On startup, the OCR loads the ANN’s saved weights to memory.
The save function is not called internally by the OCR but is up to the
server to decide when to perform a save. In our case, the server saves
the weights after each update. This is a quick and simple solution but
it is not optimal since writing to disk is time consuming. This also
prevents us from handling multiple concurrent requests since there is no
mechanism to prevent simultaneous writes to the same file. In a more
sophisticated server, saves could perhaps be done on shutdown or once
every few minutes with some form of locking or a timestamp protocol to
ensure no data loss.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_file</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="n">json_neural_network</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;theta1&quot;</span><span class="p">:[</span><span class="n">np_mat</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">np_mat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta1</span><span class="p">],</span>
        <span class="s2">&quot;theta2&quot;</span><span class="p">:[</span><span class="n">np_mat</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">np_mat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta2</span><span class="p">],</span>
        <span class="s2">&quot;b1&quot;</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layer_bias</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
        <span class="s2">&quot;b2&quot;</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_bias</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">};</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">OCRNeuralNetwork</span><span class="o">.</span><span class="n">NN_FILE_PATH</span><span class="p">,</span><span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">nnFile</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">json_neural_network</span><span class="p">,</span> <span class="n">nnFile</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_load</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_file</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">OCRNeuralNetwork</span><span class="o">.</span><span class="n">NN_FILE_PATH</span><span class="p">)</span> <span class="k">as</span> <span class="n">nnFile</span><span class="p">:</span>
        <span class="n">nn</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">nnFile</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">theta1</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">li</span><span class="p">)</span> <span class="k">for</span> <span class="n">li</span> <span class="ow">in</span> <span class="n">nn</span><span class="p">[</span><span class="s1">&#39;theta1&#39;</span><span class="p">]]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">theta2</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">li</span><span class="p">)</span> <span class="k">for</span> <span class="n">li</span> <span class="ow">in</span> <span class="n">nn</span><span class="p">[</span><span class="s1">&#39;theta2&#39;</span><span class="p">]]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_layer_bias</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nn</span><span class="p">[</span><span class="s1">&#39;b1&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_bias</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nn</span><span class="p">[</span><span class="s1">&#39;b2&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])]</span>
</pre></div>
</div>
<p class="rubric" id="conclusion">Conclusion</p>
<p>Now that we’ve learned about AI, ANNs, backpropagation, and building an
end-to-end OCR system, let’s recap the highlights of this chapter and
the big picture.</p>
<p>We started off the chapter by giving background on AI, ANNs, and roughly
what we will be implementing. We discussed what AI is and examples of
how it’s used. We saw that AI is essentially a set of algorithms or
problem-solving approaches that can provide an answer to a question in a
similar manner as a human would. We then took a look at the structure of
a Feedforward ANN. We learned that computing the output at a given node
was as simple as summing the products of the outputs of the previous
nodes and their connecting weights. We talked about how to use an ANN by
first formatting the input and partitioning the data into training and
validation sets.</p>
<p>Once we had some background, we started talking about creating a
web-based, client-server system that would handle user requests to train
or test the OCR. We then discussed how the client would interpret the
drawn pixels into an array and perform an HTTP request to the OCR server
to perform the training or testing. We discussed how our simple server
read requests and how to design an ANN by testing performance of several
hidden node counts. We finished off by going through the core training
and testing code for backpropagation.</p>
<p>Although we’ve built a seemingly functional OCR system, this chapter
simply scratches the surface of how a real OCR system might work. More
sophisticated OCR systems could have pre-processed inputs, use hybrid ML
algorithms, have more extensive design phases, or other further
optimizations.</p>
</div></div></div></div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Learn-Computer-and-Math-again</a></h1>








<h3>导航</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="blockcode-a-visual-programming-toolkit.html">500 Lines or Less | Blockcode: A visual programming toolkit</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>快速搜索</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="转向" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, timger.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="../_sources/chapters/optical-character-recognition-ocr.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>